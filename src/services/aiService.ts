/**
 * AI æœåŠ¡æ•´åˆå±‚
 * ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ AI ç›¸å…³çš„æœåŠ¡è°ƒç”¨
 */

import { ClaudeService } from './claude';
import { NovaService } from './nova';
import { SpeechService } from './speech';
import { AmazonTranscribeService } from './transcribe';
import { AmazonNovaCanvasService } from './novaCanvas';
import { SentimentAnalysis, GeneratedImage, Context } from '@/types';

export interface ProcessVoiceResult {
  transcript: string;
  sentiment: SentimentAnalysis;
  imagePrompt: string;
  generatedImage?: GeneratedImage;
}

export interface AIServiceOptions {
  enableImageGeneration?: boolean;
  imageStyle?: string;
  maxRetries?: number;
  timeout?: number;
  useAmazonServices?: boolean;
}

export class AIService {
  private static transcribeService = new AmazonTranscribeService();
  private static novaCanvasService = new AmazonNovaCanvasService();

  /**
   * å®Œæ•´çš„è¯­éŸ³å¤„ç†æµç¨‹
   * 1. è¯­éŸ³è½¬æ–‡å­—
   * 2. æƒ…æ„Ÿåˆ†æ
   * 3. ç”Ÿæˆå›¾ç‰‡æç¤ºè¯
   * 4. ç”Ÿæˆå›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
   */
  static async processVoice(
    audioBlob: Blob,
    context?: Context,
    options: AIServiceOptions = {}
  ): Promise<ProcessVoiceResult> {
    const {
      enableImageGeneration = true,
      imageStyle = 'abstract',
      maxRetries = 3,
      timeout = 60000,
      useAmazonServices = process.env.USE_AMAZON_AI_SERVICES === 'true'
    } = options;

    let transcript = '';
    let sentiment: SentimentAnalysis;
    let imagePrompt = '';
    let generatedImage: GeneratedImage | undefined;

    try {
      // æ­¥éª¤1: è¯­éŸ³è½¬æ–‡å­—
      console.log('å¼€å§‹è¯­éŸ³è½¬æ–‡å­—...');
      const transcriptionResult = await this.withTimeout(
        useAmazonServices 
          ? this.transcribeService.transcribeAudio(audioBlob)
          : SpeechService.transcribeAudio(audioBlob),
        timeout / 4,
        'è¯­éŸ³è½¬æ–‡å­—è¶…æ—¶'
      );

      transcript = transcriptionResult.text;
      console.log('è¯­éŸ³è½¬æ–‡å­—å®Œæˆ:', transcript);

      // éªŒè¯è½¬å½•ç»“æœ
      if (!transcript || transcript.trim().length === 0) {
        throw new Error('è¯­éŸ³è½¬æ–‡å­—ç»“æœä¸ºç©ºï¼Œè¯·é‡æ–°å½•åˆ¶');
      }

      // æ­¥éª¤2: æƒ…æ„Ÿåˆ†æ
      console.log('å¼€å§‹æƒ…æ„Ÿåˆ†æ...');
      sentiment = await this.withTimeout(
        ClaudeService.analyzeSentiment(transcript, context),
        timeout / 3,
        'æƒ…æ„Ÿåˆ†æè¶…æ—¶'
      );
      console.log('æƒ…æ„Ÿåˆ†æå®Œæˆ:', sentiment);

      // æ­¥éª¤3: ç”Ÿæˆå›¾ç‰‡æç¤ºè¯
      console.log('ç”Ÿæˆå›¾ç‰‡æç¤ºè¯...');
      imagePrompt = await this.withTimeout(
        ClaudeService.generateImagePrompt(transcript, sentiment, context, imageStyle),
        timeout / 4,
        'å›¾ç‰‡æç¤ºè¯ç”Ÿæˆè¶…æ—¶'
      );
      console.log('å›¾ç‰‡æç¤ºè¯ç”Ÿæˆå®Œæˆ:', imagePrompt);

      // æ­¥éª¤4: ç”Ÿæˆå›¾ç‰‡ï¼ˆå¯é€‰ï¼‰
      if (enableImageGeneration) {
        console.log('å¼€å§‹ç”Ÿæˆå›¾ç‰‡...');
        try {
          const imageResult = await this.withTimeout(
            useAmazonServices 
              ? this.novaCanvasService.generateImage(transcript, sentiment, { style: imageStyle as any })
              : this.generateImageViaAPI({
                  prompt: imagePrompt,
                  style: imageStyle,
                  width: 512,
                  height: 512,
                }),
            timeout / 2,
            'å›¾ç‰‡ç”Ÿæˆè¶…æ—¶'
          );

          if (useAmazonServices) {
            generatedImage = {
              id: `img_${Date.now()}`,
              voiceRecordId: `voice_${Date.now()}`,
              url: imageResult.url,
              prompt: imageResult.prompt,
              style: imageResult.style as any,
              createdAt: new Date(),
            };
          } else {
            generatedImage = {
              id: `img_${Date.now()}`,
              voiceRecordId: `voice_${Date.now()}`,
              url: (imageResult as any).imageUrl,
              prompt: imagePrompt,
              style: imageStyle as any,
              createdAt: new Date(),
            };
          }
          console.log('å›¾ç‰‡ç”Ÿæˆå®Œæˆ:', generatedImage.url);
        } catch (imageError) {
          console.warn('å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼Œä½†ç»§ç»­å¤„ç†:', imageError);
          // å›¾ç‰‡ç”Ÿæˆå¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹
        }
      }

      return {
        transcript,
        sentiment,
        imagePrompt,
        generatedImage,
      };

    } catch (error) {
      console.error('AI æœåŠ¡å¤„ç†å¤±è´¥:', error);
      throw new Error(`AI å¤„ç†å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  /**
   * ä»…è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼ˆä¸ç”Ÿæˆå›¾ç‰‡ï¼‰
   */
  static async analyzeSentimentOnly(
    audioBlob: Blob,
    context?: Context
  ): Promise<{ transcript: string; sentiment: SentimentAnalysis }> {
    try {
      // è¯­éŸ³è½¬æ–‡å­—
      const transcriptionResult = await SpeechService.transcribeAudio(audioBlob);
      
      if (!SpeechService.validateTranscription(transcriptionResult)) {
        throw new Error('è¯­éŸ³è½¬æ–‡å­—ç»“æœè´¨é‡ä¸ä½³');
      }

      // æƒ…æ„Ÿåˆ†æ
      const sentiment = await ClaudeService.analyzeSentiment(
        transcriptionResult.text,
        context
      );

      return {
        transcript: transcriptionResult.text,
        sentiment,
      };
    } catch (error) {
      console.error('æƒ…æ„Ÿåˆ†æå¤±è´¥:', error);
      throw new Error(`æƒ…æ„Ÿåˆ†æå¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  /**
   * ä»…ç”Ÿæˆå›¾ç‰‡
   */
  static async generateImageOnly(
    transcript: string,
    sentiment: SentimentAnalysis,
    context?: Context,
    style: string = 'abstract'
  ): Promise<GeneratedImage> {
    try {
      // ç”Ÿæˆå›¾ç‰‡æç¤ºè¯
      const imagePrompt = await ClaudeService.generateImagePrompt(
        transcript,
        sentiment,
        context,
        style
      );

      // ç”Ÿæˆå›¾ç‰‡ - é€šè¿‡APIè·¯ç”±è°ƒç”¨ï¼Œé¿å…åœ¨å‰ç«¯è®¿é—®AWSå‡­è¯
      const novaResponse = await this.generateImageViaAPI({
        prompt: imagePrompt,
        style,
        width: 512,
        height: 512,
      });

      return {
        id: `img_${Date.now()}`,
        voiceRecordId: `voice_${Date.now()}`,
        url: novaResponse.imageUrl,
        prompt: imagePrompt,
        style: style as any,
        createdAt: new Date(),
      };
    } catch (error) {
      console.error('å›¾ç‰‡ç”Ÿæˆå¤±è´¥:', error);
      throw new Error(`å›¾ç‰‡ç”Ÿæˆå¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  /**
   * æ‰¹é‡ç”Ÿæˆå¤šç§é£æ ¼çš„å›¾ç‰‡
   */
  static async generateMultipleStyles(
    transcript: string,
    sentiment: SentimentAnalysis,
    context?: Context,
    styles: string[] = ['abstract', 'artistic', 'minimalist']
  ): Promise<GeneratedImage[]> {
    const promises = styles.map(style =>
      this.generateImageOnly(transcript, sentiment, context, style)
        .catch(error => {
          console.warn(`ç”Ÿæˆ ${style} é£æ ¼å›¾ç‰‡å¤±è´¥:`, error);
          return null;
        })
    );

    const results = await Promise.all(promises);
    return results.filter((result): result is GeneratedImage => result !== null);
  }

  /**
   * é‡æ–°ç”Ÿæˆå›¾ç‰‡ï¼ˆä½¿ç”¨ä¸åŒçš„ç§å­å€¼ï¼‰
   */
  static async regenerateImage(
    imagePrompt: string,
    style: string = 'abstract'
  ): Promise<GeneratedImage> {
    try {
      const novaResponse = await this.generateImageViaAPI({
        prompt: imagePrompt,
        style,
        width: 512,
        height: 512,
      });

      return {
        id: `img_${Date.now()}`,
        voiceRecordId: `voice_${Date.now()}`,
        url: novaResponse.imageUrl,
        prompt: imagePrompt,
        style: style as any,
        createdAt: new Date(),
      };
    } catch (error) {
      console.error('é‡æ–°ç”Ÿæˆå›¾ç‰‡å¤±è´¥:', error);
      throw new Error(`é‡æ–°ç”Ÿæˆå›¾ç‰‡å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  /**
   * è·å–å¤„ç†è¿›åº¦ï¼ˆæ¨¡æ‹Ÿï¼‰
   */
  static async getProcessingProgress(taskId: string): Promise<{
    progress: number;
    stage: string;
    completed: boolean;
  }> {
    // è¿™é‡Œå¯ä»¥å®ç°çœŸå®çš„è¿›åº¦è·Ÿè¸ª
    // æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
    return {
      progress: 100,
      stage: 'completed',
      completed: true,
    };
  }

  /**
   * é€šè¿‡APIè·¯ç”±ç”Ÿæˆå›¾ç‰‡ï¼ˆé¿å…åœ¨å‰ç«¯è®¿é—®AWSå‡­è¯ï¼‰
   */
  private static async generateImageViaAPI(request: {
    prompt: string;
    style?: string;
    width?: number;
    height?: number;
  }): Promise<{ imageUrl: string; imageData?: string; metadata: any }> {
    console.log('ğŸ¨ é€šè¿‡APIè·¯ç”±ç”Ÿæˆå›¾ç‰‡:', {
      prompt: request.prompt.substring(0, 100) + (request.prompt.length > 100 ? '...' : ''),
      style: request.style
    });

    try {
      const response = await fetch('/api/image/generate', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(request),
      });

      if (!response.ok) {
        throw new Error(`å›¾ç‰‡ç”ŸæˆAPIè°ƒç”¨å¤±è´¥: ${response.status} ${response.statusText}`);
      }

      const result = await response.json();
      console.log('âœ… APIè·¯ç”±å›¾ç‰‡ç”ŸæˆæˆåŠŸï¼Œå“åº”æ•°æ®:', result);
      
      // APIè¿”å›çš„æ•°æ®ç»“æ„æ˜¯ { success: true, data: {...} }
      const imageData = result.data || result;
      
      return {
        imageUrl: imageData.imageUrl,
        imageData: imageData.imageData,
        metadata: imageData.metadata
      };
    } catch (error) {
      console.error('âŒ APIè·¯ç”±å›¾ç‰‡ç”Ÿæˆå¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * éªŒè¯ AI æœåŠ¡é…ç½®
   */
  static validateConfiguration(): {
    isValid: boolean;
    missingServices: string[];
    warnings: string[];
  } {
    const missingServices: string[] = [];
    const warnings: string[] = [];

    // æ£€æŸ¥ Claude API
    if (!process.env.CLAUDE_API_KEY) {
      missingServices.push('Claude API Key');
    }

    // æ£€æŸ¥ AWS é…ç½®
    if (!process.env.AWS_ACCESS_KEY_ID || !process.env.AWS_SECRET_ACCESS_KEY) {
      missingServices.push('AWS Credentials');
    }

    // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
    if (typeof window !== 'undefined') {
      if (!navigator.mediaDevices?.getUserMedia) {
        warnings.push('æµè§ˆå™¨ä¸æ”¯æŒéŸ³é¢‘å½•åˆ¶');
      }

      if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
        warnings.push('æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«');
      }
    }

    return {
      isValid: missingServices.length === 0,
      missingServices,
      warnings,
    };
  }

  /**
   * è¶…æ—¶åŒ…è£…å™¨
   */
  private static withTimeout<T>(
    promise: Promise<T>,
    timeoutMs: number,
    errorMessage: string
  ): Promise<T> {
    return Promise.race([
      promise,
      new Promise<never>((_, reject) =>
        setTimeout(() => reject(new Error(errorMessage)), timeoutMs)
      ),
    ]);
  }

  /**
   * è·å–æœåŠ¡çŠ¶æ€
   */
  static async getServiceStatus(): Promise<{
    speech: boolean;
    sentiment: boolean;
    imageGeneration: boolean;
  }> {
    const status = {
      speech: false,
      sentiment: false,
      imageGeneration: false,
    };

    try {
      // æµ‹è¯•è¯­éŸ³æœåŠ¡
      const mockBlob = new Blob(['test'], { type: 'audio/wav' });
      await SpeechService.transcribeAudio(mockBlob);
      status.speech = true;
    } catch {
      // è¯­éŸ³æœåŠ¡ä¸å¯ç”¨
    }

    try {
      // æµ‹è¯•æƒ…æ„Ÿåˆ†ææœåŠ¡
      await ClaudeService.analyzeSentiment('æµ‹è¯•æ–‡æœ¬');
      status.sentiment = true;
    } catch {
      // æƒ…æ„Ÿåˆ†ææœåŠ¡ä¸å¯ç”¨
    }

    try {
      // æµ‹è¯•å›¾ç‰‡ç”ŸæˆæœåŠ¡ - é€šè¿‡APIè·¯ç”±
      await this.generateImageViaAPI({ prompt: 'test prompt' });
      status.imageGeneration = true;
    } catch {
      // å›¾ç‰‡ç”ŸæˆæœåŠ¡ä¸å¯ç”¨
    }

    return status;
  }
}
